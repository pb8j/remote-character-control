<!DOCTYPE html>
<html>
<head>
    <title>Mobile Robot View</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Inter Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: 'Inter', sans-serif;
            background-color: #f0f4f8; /* Light blue-gray background */
            display: flex;
            flex-direction: column;
            height: 100vh;
            color: #333;
            padding: 10px; /* Some padding for mobile layout */
            box-sizing: border-box; /* Include padding in element's total width/height */
        }

        h1 {
            text-align: center;
            color: #2c3e50; /* Dark blue heading */
            padding: 15px;
            margin: 0;
            background-color: #ffffff;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            font-size: 1.5em;
            border-radius: 10px; /* Rounded corners for header */
            margin-bottom: 10px;
        }

        .container {
            flex-grow: 1;
            background-color: #ffffff;
            border-radius: 15px;
            box-shadow: 0 8px 25px rgba(0,0,0,0.15);
            background: linear-gradient(145deg, #f0f0f0, #ffffff);
            border: 1px solid #e0e0e0;
            padding: 20px;
            text-align: center;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .status-text {
            font-size: 1em; /* Adjusted font size */
            color: #555;
            margin-bottom: 8px; /* Reduced margin */
        }
        .status-value {
            font-weight: bold;
            color: #007bff;
        }

        .device-id-text {
            font-size: 0.9em; /* Adjusted font size */
            color: #777;
            margin-bottom: 20px; /* Reduced margin */
            word-break: break-all; /* Ensure long device IDs wrap on small screens */
        }
        .device-id-value {
            color: #34495e;
        }

        .mode-toggle-container {
            margin-bottom: 20px; /* Reduced margin */
            display: flex;
            flex-wrap: wrap; /* Allow buttons to wrap on smaller screens */
            justify-content: center;
            gap: 10px; /* Reduced gap between buttons */
        }

        .mode-button {
            padding: 10px 20px; /* Reduced padding */
            border: 2px solid #007bff;
            border-radius: 25px; /* Slightly smaller border-radius */
            background-color: #ffffff;
            color: #007bff;
            cursor: pointer;
            font-size: 0.9em; /* Adjusted font size */
            font-weight: 600;
            transition: all 0.3s ease;
            outline: none;
            box-shadow: 0 2px 5px rgba(0, 123, 255, 0.2);
            flex-grow: 1; /* Allow buttons to grow and fill space */
            max-width: calc(50% - 10px); /* Limit width for two columns on wider mobile screens */
        }
        .mode-button-active {
            background-color: #007bff;
            color: white;
            border-color: #0056b3;
            box-shadow: 0 4px 10px rgba(0, 123, 255, 0.4);
        }

        .video-container {
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.08);
            width: 100%; /* Make video container fill parent width */
            height: auto; /* Allow height to adjust */
            aspect-ratio: 16 / 9; /* Maintain a 16:9 aspect ratio for the video container */
            margin: 0 auto;
            background-color: #f5f5f5;
        }
        .video-stream {
            width: 100%;
            height: 100%; /* Make video fill its container */
            display: block;
            object-fit: cover; /* Cover the container while maintaining aspect ratio */
        }

        .urdf-container {
            width: 100%; /* Make URDF container fill parent width */
            height: 300px; /* Fixed height for URDF container, you might adjust this */
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            margin: 0 auto;
            overflow: hidden;
            background-color: #f5f5f5;
            box-shadow: 0 4px 15px rgba(0,0,0,0.08);
            position: relative; /* For spinner and overlay */
        }
        .urdf-container canvas {
            display: block;
            width: 100% !important;
            height: 100% !important;
            object-fit: contain;
        }

        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            width: 36px;
            height: 36px;
            border-radius: 50%;
            border-left-color: #007bff;
            animation: spin 1s ease infinite;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 5;
        }

        @keyframes spin {
            0% { transform: translate(-50%, -50%) rotate(0deg); }
            100% { transform: translate(-50%, -50%) rotate(360deg); }
        }

        #joint-angles-display {
            position: absolute;
            bottom: 10px;
            left: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 8px 12px;
            border-radius: 8px;
            font-size: 0.8em;
            max-height: 25%; /* Limit height if many joints */
            overflow-y: auto;
            pointer-events: none; /* Allows interaction with canvas below */
            z-index: 10;
            text-align: left;
        }
        #joint-angles-display div {
            margin-bottom: 2px;
        }

        /* Custom Message Box Styles */
        .message-box {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: #fff;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
            z-index: 1000;
            text-align: center;
            min-width: 250px;
            max-width: 90%;
        }
        .message-box button {
            background-color: #007bff;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            margin-top: 15px;
            font-size: 1em;
            transition: background-color 0.3s ease;
        }
        .message-box button:hover {
            background-color: #0056b3;
        }


        @media (max-width: 480px) {
            .mode-button {
                max-width: 100%; /* Stack buttons on top of each other on very small screens */
            }
            .urdf-container {
                height: 250px; /* Reduce height for very small screens */
            }
        }
    </style>
</head>
<body>
    <h1>Mobile Robot View</h1>

    <div class="container">
        <p class="status-text">Status: <span id="status-text" class="status-value">Connecting to server...</span></p>
        <p class="device-id-text">Your Device ID: <strong id="phone-device-id" class="device-id-value">Generating...</strong></p>

        <div class="mode-toggle-container">
            <button id="video-mode-button" class="mode-button mode-button-active">Show Camera Feed</button>
            <button id="urdf-mode-button" class="mode-button">Show URDF Robot</button>
        </div>

        <!-- Video Container -->
        <div id="video-display-area" class="video-container">
            <video id="local-video" class="video-stream" autoplay playsInline muted></video>
        </div>

        <!-- URDF Container -->
        <div id="urdf-display-area" class="urdf-container hidden">
            <div id="urdf-canvas-container" style="width: 100%; height: 100%;"></div>
            <div id="loading-spinner" class="spinner"></div>
            <div id="joint-angles-display">
                <strong>Joint Angles:</strong>
                <!-- Joint angles will be dynamically added here -->
            </div>
        </div>
    </div>

    <!-- Custom Message Box -->
    <div id="message-box" class="message-box">
        <p id="message-text"></p>
        <button onclick="hideMessageBox()">OK</button>
    </div>

    <!-- Libraries -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    <script src="https://unpkg.com/three-urdf-loader@0.0.12/dist/URDFLoader.js"></script>

    <script>
        // --- Configuration ---
        const FLASK_APP_URL = "https://remote-character-control.onrender.com";
        const PHONE_DEVICE_ID = `phone-${Math.random().toString(36).substring(2, 9)}`; // Unique ID for this phone instance
        // Corrected paths to point to the Robotiq 85 gripper URDF in the 'robots' folder
        const ROBOT_URDF_PATH = "/robots/robotiq_arg85_description.URDF"; // Path relative to Flask static root
        const ROBOT_PACKAGE_PATH = "/robots/"; // Path for meshes relative to Flask static root (where your STL files are inside 'meshes' folder under 'robots')

        // --- Global Variables ---
        let socket;
        let localStream; // Camera and microphone stream
        let peerConnection; // WebRTC Peer Connection
        let displayMode = 'video'; // 'video' or 'urdf'

        // Three.js for URDF Visualization
        let scene, camera, renderer, controls;
        let robotModel; // The loaded Robotiq 85 Gripper URDF model
        const jointDisplays = {}; // To update joint angle text dynamically on screen

        // Elements
        const statusTextElement = document.getElementById('status-text');
        const phoneDeviceIdElement = document.getElementById('phone-device-id');
        const localVideoElement = document.getElementById('local-video');
        const videoDisplayArea = document.getElementById('video-display-area');
        const urdfDisplayArea = document.getElementById('urdf-display-area');
        const loadingSpinner = document.getElementById('loading-spinner');
        const jointAnglesDisplay = document.getElementById('joint-angles-display');


        // --- Custom Message Box Functions (replaces alert/confirm) ---
        function showMessageBox(message) {
            document.getElementById('message-text').textContent = message;
            document.getElementById('message-box').style.display = 'block';
        }

        function hideMessageBox() {
            document.getElementById('message-box').style.display = 'none';
        }

        // --- Three.js Initialization for Robotiq 85 URDF ---
        function initThreeJS() {
            // Scene
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0xe3f2fd); // Lighter blue background

            // Camera
            // Adjusted camera for viewing the small gripper model
            camera = new THREE.PerspectiveCamera(75, urdfDisplayArea.offsetWidth / urdfDisplayArea.offsetHeight, 0.001, 10);
            camera.position.set(0.1, 0.1, 0.1); // Closer initial position

            // Renderer
            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(urdfDisplayArea.offsetWidth, urdfDisplayArea.offsetHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            document.getElementById('urdf-canvas-container').appendChild(renderer.domElement);

            // OrbitControls
            controls = new THREE.OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.dampingFactor = 0.25;
            controls.screenSpacePanning = false;
            controls.maxPolarAngle = Math.PI / 2;

            // Lighting
            const ambientLight = new THREE.AmbientLight(0x404040, 2);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
            directionalLight.position.set(0.5, 0.5, 0.5).normalize(); // Adjusted for gripper
            scene.add(directionalLight);
            const directionalLight2 = new THREE.DirectionalLight(0xffffff, 0.5);
            directionalLight2.position.set(-0.5, -0.5, -0.5).normalize(); // Adjusted for gripper
            scene.add(directionalLight2);

            // URDF Loader
            const loader = new THREE.URDFLoader();
            loader.packages = {
                'robotiq_arg85_description': ROBOT_PACKAGE_PATH // Package name from URDF, mapped to path
            };
            loader.workingPath = ROBOT_PACKAGE_PATH; // Set working path for relative mesh paths in URDF

            loadingSpinner.style.display = 'block'; // Show spinner

            loader.load(ROBOT_URDF_PATH, result => {
                robotModel = result;
                scene.add(robotModel);
                console.log('Mobile View: Robotiq 85 Gripper Loaded:', robotModel);

                const scaleFactor = 100; // Gripper is small, scale it up significantly
                robotModel.scale.set(scaleFactor, scaleFactor, scaleFactor);
                robotModel.position.set(0, -0.05 * scaleFactor, 0); // Adjust vertical offset

                // Adjust camera to view the loaded robot (gripper)
                const box = new THREE.Box3().setFromObject(robotModel);
                const center = box.getCenter(new THREE.Vector3());
                const size = box.getSize(new THREE.Vector3());

                // Set camera target to the center of the gripper
                controls.target.copy(center);
                // Position camera for better view of gripper
                camera.position.set(center.x + 0.1, center.y + 0.1, center.z + 0.1); // Slightly offset view
                camera.lookAt(center); // Look at the center of the gripper

                controls.update(); // Update controls after changing target/position

                camera.far = 10; // Adjust far clipping plane
                camera.near = 0.001; // Adjust near clipping plane
                camera.updateProjectionMatrix();

                console.log("Mobile View: Camera adjusted for gripper. Center:", center, "Position:", camera.position);

                loadingSpinner.style.display = 'none'; // Hide spinner

                // Populate joint displays for Robotiq 85 gripper
                jointAnglesDisplay.innerHTML = '<strong>Joint Angles:</strong>';
                // Only expect 'finger_joint' for direct control, others are mimicked
                const controlledJointName = 'finger_joint';
                const joint = robotModel.joints[controlledJointName];
                if (joint && joint.jointType !== 'fixed') {
                    const div = document.createElement('div');
                    div.id = `joint-${controlledJointName}`;
                    div.textContent = `${controlledJointName.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase())}: ${joint.jointValue.toFixed(3)}`;
                    jointAnglesDisplay.appendChild(div);
                    jointDisplays[controlledJointName] = div;
                } else {
                     // Add placeholder for other joints that might be defined in URDF but not directly controlled
                    const placeholderJoints = ['finger_joint_2', 'left_inner_knuckle_joint', 'right_inner_knuckle_joint', 'left_inner_finger_joint', 'right_inner_finger_joint', 'left_outer_knuckle_joint', 'right_outer_knuckle_joint'];
                    placeholderJoints.forEach(jName => {
                        if (robotModel.joints[jName]) {
                            const div = document.createElement('div');
                            div.id = `joint-${jName}`;
                            div.textContent = `${jName.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase())}: ${robotModel.joints[jName].jointValue.toFixed(3)}`;
                            jointAnglesDisplay.appendChild(div);
                            jointDisplays[jName] = div;
                        }
                    });
                }


            },
            xhr => { console.log(`URDF loading: ${(xhr.loaded / xhr.total * 100).toFixed(2)}%`); },
            error => {
                console.error('Mobile View: Error loading URDF:', error);
                showMessageBox('Failed to load Robotiq 85 gripper model. Check URDF path and mesh files and server.');
                loadingSpinner.style.display = 'none';
            });

            // Animation loop
            const animate = () => {
                requestAnimationFrame(animate);
                controls.update();
                renderer.render(scene, camera);
                // No specific hexapod movement commands to apply here anymore
            };
            animate();

            // Handle window resize
            window.addEventListener('resize', () => {
                camera.aspect = urdfDisplayArea.offsetWidth / urdfDisplayArea.offsetHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(urdfDisplayArea.offsetWidth, urdfDisplayArea.offsetHeight);
            });
        }

        // --- WebRTC and Socket.IO Setup ---
        async function setupWebRTCAndSocket() {
            phoneDeviceIdElement.textContent = PHONE_DEVICE_ID;

            socket = io(FLASK_APP_URL);

            socket.on("connect", () => {
                statusTextElement.textContent = "Connected to server. Registering phone...";
                socket.emit("register_phone", PHONE_DEVICE_ID);
            });

            socket.on("connect_error", (err) => {
                console.error("Socket.IO Connect Error:", err);
                statusTextElement.textContent = `Connection Error: ${err.message}`;
                showMessageBox(`Connection Error: ${err.message}. Please check backend.`);
            });

            socket.on("start_webrtc_offer", async ({ requestingLaptopSocketId }) => {
                statusTextElement.textContent = "Laptop requested stream. Setting up WebRTC...";
                await setupPeerConnection(requestingLaptopSocketId);
            });

            socket.on("sdp_answer_from_laptop", async (sdpAnswer) => {
                statusTextElement.textContent = "Received SDP Answer. Establishing connection...";
                if (peerConnection && peerConnection.remoteDescription === null) {
                    await peerConnection.setRemoteDescription(new RTCSessionDescription(sdpAnswer));
                    console.log("Phone: Remote description set (Answer).");
                }
            });

            socket.on("ice_candidate_from_laptop", async (candidate) => {
                if (peerConnection && candidate) {
                    try {
                        await peerConnection.addIceCandidate(candidate);
                        console.log("Phone: Added remote ICE candidate.");
                    } catch (e) {
                        console.error("Phone: Error adding remote ICE candidate:", e);
                    }
                }
            });

            // Listener for general control commands (e.g., for hexapod movement) - now largely ignored for gripper
            socket.on("control", (cmd) => {
                console.log(`Phone: Received command: ${cmd}. (Note: Movement commands are ignored for gripper model.)`);
                // No action needed for gripper for these commands
            });

            // Listener for specific joint angle updates (e.g., from gripper control on laptop)
            socket.on('joint_angle_updated', (data) => {
                const { joint_name, angle } = data;
                console.log(`Mobile View: Received joint update for ${joint_name}: ${angle} radians`);
                if (robotModel && robotModel.joints[joint_name]) {
                    robotModel.joints[joint_name].setJointValue(angle);
                    if (jointDisplays[joint_name]) {
                        jointDisplays[joint_name].textContent = `${joint_name.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase())}: ${angle.toFixed(3)}`;
                    }
                }
            });

            // Receive initial joint states on connect
            socket.on('initial_joint_states', (initialStates) => {
                console.log('Mobile View: Received initial joint states:', initialStates);
                if (robotModel) {
                    for (const jointName in initialStates) {
                        if (robotModel.joints[jointName]) {
                            robotModel.joints[jointName].setJointValue(initialStates[jointName]);
                            if (jointDisplays[jointName]) {
                                jointDisplays[jointName].textContent = `${jointName.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase())}: ${initialStates[jointName].toFixed(3)}`;
                            }
                        }
                    }
                }
            });

            socket.on("disconnect", () => {
                statusTextElement.textContent = "Disconnected from server.";
                console.log("Phone: Disconnected from server.");
                stopLocalStream();
                if (peerConnection) {
                    peerConnection.close();
                    peerConnection = null;
                }
            });

            // Get local camera stream on initialization
            try {
                localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                if (localVideoElement) {
                    localVideoElement.srcObject = localStream;
                }
            } catch (err) {
                statusTextElement.textContent = `Camera access denied or unavailable: ${err.message}`;
                console.error("Camera error:", err);
                showMessageBox("Camera access denied or unavailable. Please allow camera permissions.");
            }
        }

        function stopLocalStream() {
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
                localStream = null;
            }
            if (localVideoElement) {
                localVideoElement.srcObject = null;
            }
        }

        async function setupPeerConnection(requestingLaptopSocketId) {
            if (peerConnection) {
                peerConnection.close();
            }

            const pc = new RTCPeerConnection({
                iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
            });
            peerConnection = pc;

            pc.oniceconnectionstatechange = () => {
                console.log('Phone ICE connection state:', pc.iceConnectionState);
                statusTextElement.textContent = `ICE State: ${pc.iceConnectionState}`;
            };

            if (localStream) {
                localStream.getTracks().forEach(track => pc.addTrack(track, localStream));
                console.log("Phone: Local stream added to PeerConnection.");
            } else {
                console.error("Phone: No local stream found to add to PeerConnection.");
                statusTextElement.textContent = "Error: No local stream to start WebRTC.";
                showMessageBox("Error: Could not access local camera stream to start WebRTC. Check permissions.");
                return;
            }

            pc.onicecandidate = (event) => {
                if (event.candidate) {
                    console.log("Phone: Sending ICE candidate to laptop.");
                    socket.emit("ice_candidate_from_phone", {
                        candidate: event.candidate,
                        phoneDeviceId: PHONE_DEVICE_ID,
                        requestingLaptopSocketId: requestingLaptopSocketId
                    });
                }
            };

            try {
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);
                console.log("Phone: Sending SDP Offer to laptop.");
                socket.emit("sdp_offer_from_phone", {
                    sdpOffer: offer,
                    phoneDeviceId: PHONE_DEVICE_ID,
                    requestingLaptopSocketId: requestingLaptopSocketId
                });
                statusTextElement.textContent = "Offer sent. Waiting for answer...";
            } catch (error) {
                console.error("Phone: Error creating or sending offer:", error);
                statusTextElement.textContent = `Error setting up WebRTC: ${error.message}`;
                showMessageBox(`Error setting up WebRTC: ${error.message}`);
            }
        }


        // --- UI Event Listeners ---
        document.getElementById('video-mode-button').addEventListener('click', () => {
            displayMode = 'video';
            videoDisplayArea.classList.remove('hidden');
            urdfDisplayArea.classList.add('hidden');
            document.getElementById('video-mode-button').classList.add('mode-button-active');
            document.getElementById('urdf-mode-button').classList.remove('mode-button-active');
        });

        document.getElementById('urdf-mode-button').addEventListener('click', () => {
            displayMode = 'urdf';
            videoDisplayArea.classList.add('hidden');
            urdfDisplayArea.classList.remove('hidden');
            document.getElementById('urdf-mode-button').classList.add('mode-button-active');
            document.getElementById('video-mode-button').classList.remove('mode-button-active');
        });


        // --- Initialization on Window Load ---
        window.onload = function() {
            initThreeJS();
            setupWebRTCAndSocket();
        };

    </script>
</body>
</html>
